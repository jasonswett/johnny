#!/usr/bin/env ruby

require File.expand_path('../../config/environment', __FILE__)

def with_token(value, &block)
  token = Token.find_by(value: value)

  if token.present?
    block.call(token)
  else
    puts "No such token '#{value}'. Sorry bro"
  end
end

case ARGV[0]
when "index"
  book_collection = BookCollection.new
  book_collection.index!
when "sentences"
  puts "Deleting existing sentences (#{Sentence.count})..."
  Sentence.delete_all

  Corpus.all.each do |corpus|
    corpus.sentences.each do |sentence|
      puts sentence
      sentence.save
    end
  end
when "edges"
  puts "Deleting existing edges..."
  Edge.delete_all

  puts "Saving new edges..."
  Sentence.find_each do |sentence|
    puts sentence
    sentence.edges
  end
when "tokens"
  Token.most_frequent_first.limit(30).each do |token|
    puts "#{token.value} (#{token.annotations['frequency']})"
  end
when "token"
  with_token(ARGV[1]) do |token|
    puts token.details
  end
when "related"
  token = Token.f(ARGV[1])
  puts token.related.map(&:value).join("\n")
when "followers"
  with_token(ARGV[1]) do |token|
    puts token.followers.join("\n")
  end
when "pos"
  part_of_speech = ARGV[1]
  Token.part_of_speech(part_of_speech).each do |token|
    puts "#{token.value}"
  end
when "relabel"
  token_value, part_of_speech = ARGV[1], ARGV[2]
  token = Token.find_by(value: token_value)
  puts token.part_of_speech
  token.annotations["part_of_speech"] = part_of_speech
  token.save!
  puts token.part_of_speech
when "analyze"
  words = ARGV[1..-1]
  sentence = Sentence.new(value: words.join(" "))
  puts sentence.tokens.flat_map(&:parts_of_speech).join(" ")
when "eval"
  parts_of_speech = ARGV[1..-1]
  expression_mask = ExpressionMask.new(parts_of_speech.join(" "))
  puts expression_mask.evaluate
when "tag_parts_of_speech"
  puts "Deleting parts of speech (#{PartOfSpeechTag.count})..."
  PartOfSpeechTag.delete_all
  puts "Tagging..."
  PartOfSpeechTag.tag_all
  puts "Done"
when "sample_contexts"
  with_token(ARGV[1]) do |token|
    puts ExpressionMask.sample_contexts(token)
  end
when "generate"
  count = ARGV[1].to_i
  #puts "tokens: #{Token.count}"
  #puts "edges: #{Edge.count}"

  #PartOfSpeechTag.tag_nouns
  token = Token.f(ARGV[2])

  count.times do
    puts ExpressionMask.generate_sentence
  end
when "chain"
  TokenChain.generate
else
  puts "Invalid input"
end

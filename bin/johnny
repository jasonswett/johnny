#!/usr/bin/env ruby

require File.expand_path('../../config/environment', __FILE__)

def with_token(value, &block)
  token = Token.find_by(value: value)

  if token.present?
    block.call(token)
  else
    puts "No such token '#{value}'. Sorry bro"
  end
end

case ARGV[0]
when "index"
  book_collection = BookCollection.new
  book_collection.index!
when "edges"
  puts "Deleting existing edges..."
  Edge.delete_all

  puts "Saving new edges..."
  Corpus.all.flat_map(&:sentences).each do |sentence|
    puts sentence
    sentence.edges
  end
when "tokens"
  Token.most_frequent_first.limit(30).each do |token|
    puts "#{token.value} (#{token.annotations['frequency']})"
  end
when "token"
  with_token(ARGV[1]) do |token|
    puts token.details
  end
when "related"
  tokens = Token.where(value: ARGV[1..-1])
  puts Token.related(tokens).map(&:value).join(", ")
when "followers"
  with_token(ARGV[1]) do |token|
    puts token.followers.join(", ")
  end
when "pos"
  part_of_speech = ARGV[1]
  Token.part_of_speech(part_of_speech).limit(30).each do |token|
    puts "#{token.value} (#{token.annotations['frequency']})"
  end
when "relabel"
  token_value, part_of_speech = ARGV[1], ARGV[2]
  token = Token.find_by(value: token_value)
  puts token.part_of_speech
  token.annotations["part_of_speech"] = part_of_speech
  token.save!
  puts token.part_of_speech
when "analyze"
  words = ARGV[1..-1]
  sentence = Sentence.new(words.join(" "))
  puts sentence.tokens.flat_map(&:parts_of_speech).join(" ")
when "eval"
  parts_of_speech = ARGV[1..-1]
  expression_mask = ExpressionMask.new(parts_of_speech.join(" "))
  puts expression_mask.evaluate
when "tag_parts_of_speech"
  PartOfSpeechTag.delete_all
  PartOfSpeechTag.tag_all
when "sample_contexts"
  with_token(ARGV[1]) do |token|
    puts ExpressionMask.sample_contexts(token)
  end
when "generate"
  count = ARGV[1].to_i
  puts "tokens: #{Token.count}"
  puts "edges: #{Edge.count}"

  ARGV[2..-1].each do |value|
    #token = Token.all.sample
    token = Token.f(value)

    count.times do
      next unless token.present?
      print "#{token} "
      edge = token.edges.order("distance asc, count desc")[0..4].sample
      next unless edge.present?
      next if edge.token_2.value == edge.token_1.value
      next if edge.token_2.value == token.value
      token = edge.token_2
    end
    puts
  end
else
  puts "Invalid input"
end
